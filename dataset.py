import os
import torch
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, Dataset, Subset


class MalwareDataset(Dataset):
    def __init__(self, max_len, ben_dir='data/benign', mal_dir='data/malicious'):
        self.ben_dir = ben_dir
        self.mal_dir = mal_dir
        self.ben_files = sorted(os.listdir(ben_dir))
        self.mal_files = sorted(os.listdir(mal_dir))
        self.max_len = max_len

    def __getitem__(self, index):
        try:
            file_path = os.path.join(self.ben_dir, self.ben_files[index])
            label = 0
        except IndexError:
            file_path = os.path.join(self.mal_dir, self.mal_files[index - len(self.ben_files)])
            label = 1
        with open(file_path, "rb") as f:
            seq = [byte for byte in f.read()]
            seq_len = len(seq)
            if seq_len < self.max_len:
                seq = seq + [0] * (self.max_len - seq_len)
            else:
                seq = seq[:self.max_len]
        return torch.tensor(seq), torch.tensor(label)

    def __len__(self):
        return len(self.ben_files) + len(self.mal_files)


def create_loaders(dataset, batch_size, valid_size):
    train_indices, valid_indices = create_indices(dataset, valid_size)
    train_dataset = Subset(dataset, indices=train_indices)
    valid_dataset = Subset(dataset, indices=valid_indices)
    train_loader = DataLoader(train_dataset,
                              batch_size=batch_size,
                              shuffle=True)
    valid_loader = DataLoader(valid_dataset,
                              batch_size=batch_size,
                              shuffle=True)
    return train_loader, valid_loader


def create_indices(dataset, valid_size):
    len_ben = len(dataset.ben_files)
    len_mal = len(dataset.mal_files)
    ben_indices = range(len_ben)
    mal_indices = range(len_ben, len_ben + len_mal)
    train_ben_indices, valid_ben_indices = train_test_split(ben_indices,
                                                            test_size=valid_size,
                                                            shuffle=True)

    train_mal_indices, valid_mal_indices = train_test_split(mal_indices,
                                                            test_size=valid_size,
                                                            shuffle=True)
    train_indices = train_ben_indices + train_mal_indices
    valid_indices = valid_ben_indices + valid_mal_indices
    return train_indices, valid_indices


'''
def collate_fn(batch):
    batch_x = pad_sequences([sample[0] for sample in batch], max_len=1024)
    batch_y = torch.tensor([sample[1] for sample in batch])
    return batch_x, batch_y


def pad_sequences(sequences, max_len=None, padding_value=0):
    if max_len is None:
        max_len = max([len(seq) for seq in sequences])
    batch_size = len(sequences)
    padded = torch.full((batch_size, max_len), padding_value, dtype=torch.long)
    for i, seq in enumerate(sequences):
        seq_len = len(seq)
        if seq_len < max_len:
            padded[i, :seq_len] = seq
        else:
            padded[i, :max_len] = seq[:max_len]
    return padded
'''


def test():
    train_loader, _ = create_loaders(batch_size=16, valid_size=0.2)
    it = iter(train_loader)
    inputs, labels = next(it)
    print(inputs.shape, labels.shape)


if __name__ == '__main__':
    test()
