import os
import random
import shutil
import numpy as np
import torch
from torch import optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
from tqdm import tqdm
from plot_utils import plot_loss_history, plot_accu_history
from dataset import MalwareDataset, create_loaders
from model import MalConv


def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True


def train(model, train_loader, valid_loader, device, title,
          lr=0.001, num_epochs=50, verbose=True, resume=False):
    """
    Train the model.
    """
    checkpoint_path = os.path.join('results', 'weights', f'{title}_checkpoint.pth')
    min_loss_path = os.path.join('results', 'weights', f'{title}_min_loss.pth')
    max_accu_path = os.path.join('results', 'weights', f'{title}_max_accu.pth')

    train_loss_history = []
    train_accu_history = []
    valid_loss_history = []
    valid_accu_history = []

    # criterion = torch.nn.BCEWithLogitsLoss()
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)

    if resume:
        checkpoint = torch.load(checkpoint_path)
        model.load_state_dict(checkpoint['model'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        start_epoch = checkpoint['epoch'] + 1
        min_loss = checkpoint['loss']
        max_accu = checkpoint['accu']
    else:
        start_epoch = 1
        min_loss = float('inf')
        max_accu = 0

    # early_stopping_cnt = 1

    for epoch in range(start_epoch, num_epochs + 1):
        # train the model
        model.train()
        train_loss, train_accu = run_epoch(model, train_loader, device, criterion, optimizer)
        train_loss_history.append(train_loss)
        train_accu_history.append(train_accu)

        # validate the model
        model.eval()
        with torch.no_grad():
            valid_loss, valid_accu = run_epoch(model, valid_loader, device, criterion)
        valid_loss_history.append(valid_loss)
        valid_accu_history.append(valid_accu)

        if verbose:
            tqdm.write(f'Epoch [{epoch}/{num_epochs}] '
                       f'Train Loss: {train_loss:.4f} '
                       f'Train Accu: {train_accu:.4f} '
                       f'Valid Loss: {valid_loss:.4f} '
                       f'Valid Accu: {valid_accu:.4f}')

        # adjust the learning rate
        scheduler.step(valid_loss)

        # save the model
        torch.save({'model': model.state_dict(),
                    'optimizer': optimizer.state_dict(),
                    'epoch': epoch,
                    'loss': valid_loss,
                    'accu': valid_accu}, checkpoint_path)
        if min_loss > valid_loss:
            shutil.copyfile(checkpoint_path, min_loss_path)
            min_loss = valid_loss
        if max_accu < valid_accu:
            shutil.copyfile(checkpoint_path, max_accu_path)
            max_accu = valid_accu

        plot_loss_history(train_loss_history, valid_loss_history, title)
        plot_accu_history(train_accu_history, valid_accu_history, title)

        '''
        # early stopping
        if len(valid_accu_history) > 0:
            if valid_accu < valid_accu_history[-1]:
                early_stopping_cnt += 1
            else:
                early_stopping_cnt = 0
            if early_stopping_cnt > patience:
                print(f'Early stopping at the end of the epoch {epoch}.')
                break
        '''


def run_epoch(model, loader, device, criterion, optimizer=None):
    losses = 0
    corrects = 0

    for inputs, labels in tqdm(loader):
        inputs = inputs.to(device)
        labels = labels.to(device)
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        if optimizer:
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        losses += loss.item()
        predicts = torch.argmax(outputs, dim=1).long()
        corrects += (predicts == labels).sum().item()

    return losses / len(loader), corrects / len(loader.dataset)


def main():
    set_seed(1)
    os.makedirs(os.path.join('results', 'images'), exist_ok=True)
    os.makedirs(os.path.join('results', 'weights'), exist_ok=True)

    device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')
    max_len = int(1.5 * 1024 * 1024)
    window_size = 512

    dataset = MalwareDataset(max_len=max_len)
    train_loader, valid_loader = create_loaders(dataset, batch_size=32, valid_size=0.2)
    model = MalConv(max_len=max_len, window_size=window_size).to(device)

    train(model, train_loader, valid_loader, device, 'malconv', num_epochs=50)


if __name__ == '__main__':
    main()
