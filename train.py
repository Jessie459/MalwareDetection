import os
import random
import shutil
import numpy as np
import torch
import torch.cuda.amp
from torch import optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
from tqdm import tqdm
from utils import plot_loss_history, plot_accu_history
from dataset import MalwareDataset, create_loaders
from model import MalConv


def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True


device = torch.device('cuda:1')
scaler = torch.cuda.amp.GradScaler()


def train(model, train_loader, valid_loader, title,
          lr=0.001, num_epochs=50, resume=False):
    """
    Train the model.
    """
    checkpoint_path = os.path.join('results', 'weights', f'{title}_checkpoint.pth')
    min_loss_path = os.path.join('results', 'weights', f'{title}_min_loss.pth')
    max_accu_path = os.path.join('results', 'weights', f'{title}_max_accu.pth')

    train_loss_history = []
    train_accu_history = []
    valid_loss_history = []
    valid_accu_history = []

    criterion = torch.nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)

    if resume:
        checkpoint = torch.load(checkpoint_path)
        model.load_state_dict(checkpoint['model'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        start_epoch = checkpoint['epoch'] + 1
        min_loss = checkpoint['loss']
        max_accu = checkpoint['accu']
    else:
        start_epoch = 1
        min_loss = float('inf')
        max_accu = 0

    # counter for early stopping
    counter = 0

    for epoch in range(start_epoch, num_epochs + 1):
        # train the model
        model.train()
        train_loss, train_accu = run_epoch(model, train_loader, criterion, optimizer)
        train_loss_history.append(train_loss)
        train_accu_history.append(train_accu)

        # validate the model
        model.eval()
        with torch.no_grad():
            valid_loss, valid_accu = run_epoch(model, valid_loader, criterion)
        valid_loss_history.append(valid_loss)
        valid_accu_history.append(valid_accu)

        tqdm.write(f'Epoch [{epoch}/{num_epochs}] '
                   f'Train Loss: {train_loss:.4f} '
                   f'Train Accu: {train_accu:.4f} '
                   f'Valid Loss: {valid_loss:.4f} '
                   f'Valid Accu: {valid_accu:.4f}')

        # adjust the learning rate
        scheduler.step(valid_loss)

        # save the model
        torch.save({'model': model.state_dict(),
                    'optimizer': optimizer.state_dict(),
                    'epoch': epoch,
                    'loss': valid_loss,
                    'accu': valid_accu}, checkpoint_path)
        if min_loss > valid_loss:
            shutil.copyfile(checkpoint_path, min_loss_path)
            min_loss = valid_loss
        if max_accu < valid_accu:
            shutil.copyfile(checkpoint_path, max_accu_path)
            max_accu = valid_accu

        # early stopping
        if len(valid_accu_history) > 0:
            if valid_accu < valid_accu_history[-1]:
                counter += 1
            else:
                counter = 0

            if counter >= 5:
                print(f'Early stopping at the end of the epoch {epoch}.')
                break

    plot_loss_history(train_loss_history, valid_loss_history, title)
    plot_accu_history(train_accu_history, valid_accu_history, title)


def run_epoch(model, loader, criterion, optimizer=None):
    losses = 0
    corrects = 0

    for inputs, labels in tqdm(loader):
        inputs = inputs.to(device)
        labels = labels.to(device)

        with torch.cuda.amp.autocast():
            outputs = model(inputs)
            loss = criterion(outputs, labels)

        if optimizer:
            optimizer.zero_grad()
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

        losses += loss.item()
        predicts = torch.argmax(outputs, dim=1).long()
        corrects += (predicts == labels).sum().item()

    return losses / len(loader), corrects / len(loader.dataset)


def main():
    set_seed(1)
    os.makedirs(os.path.join('results', 'images'), exist_ok=True)
    os.makedirs(os.path.join('results', 'weights'), exist_ok=True)

    max_len = 1024 * 1024
    window_size = 512
    batch_size = 32

    dataset = MalwareDataset(max_len=max_len)
    train_loader, valid_loader = create_loaders(dataset, batch_size=batch_size)
    model = MalConv(window_size=window_size).to(device)

    train(model, train_loader, valid_loader, title='malconv', num_epochs=50)


if __name__ == '__main__':
    main()
